{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZrdaqhByWTk",
        "outputId": "692e8ae2-94f1-429e-9a6b-908f92eafe0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.23.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.16.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7906 sha256=0d058f896cb70ceaec563bcf2cad7d1a5ff57031cfe1570dac2b85652fc84658\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/f4/e7/643fc5f932ec2ff92997f43f007660feb23f948aa8486f1107\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ]
        }
      ],
      "source": [
        "!pip install idx2numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jXqIjQIv9Zg",
        "outputId": "add5df64-d1dc-43d2-fa5e-d35fc1ba4ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep-Learning'...\n",
            "remote: Enumerating objects: 381, done.\u001b[K\n",
            "remote: Counting objects: 100% (381/381), done.\u001b[K\n",
            "remote: Compressing objects: 100% (273/273), done.\u001b[K\n",
            "remote: Total 381 (delta 197), reused 288 (delta 104), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (381/381), 11.12 MiB | 15.04 MiB/s, done.\n",
            "Resolving deltas: 100% (197/197), done.\n"
          ]
        }
      ],
      "source": [
        "# !rm -rf /content/Deep-Learning\n",
        "!git clone https://github.com/QuangDiy/Deep-Learning.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn2R6so3yOxY",
        "outputId": "3380bc0e-498c-4a1a-d889-0ead5500e0b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50], loss: 1.6480, accuracy: 0.4396: 100% 375/375 [00:08<00:00, 43.43it/s] \n",
            "Epoch 1/50 | Training Loss: 1.647985 | Val Loss: 0.958873 | Val Acc: 0.658245\n",
            "Validation loss decreased (inf --> 0.958873).  Saving model ...\n",
            "Epoch [2/50], loss: 0.6443, accuracy: 0.7550: 100% 375/375 [00:01<00:00, 242.43it/s]\n",
            "Epoch 2/50 | Training Loss: 0.644337 | Val Loss: 0.578352 | Val Acc: 0.773050\n",
            "Validation loss decreased (0.958873 --> 0.578352).  Saving model ...\n",
            "Epoch [3/50], loss: 0.5567, accuracy: 0.7780: 100% 375/375 [00:01<00:00, 247.48it/s]\n",
            "Epoch 3/50 | Training Loss: 0.556704 | Val Loss: 0.558246 | Val Acc: 0.776319\n",
            "Validation loss decreased (0.578352 --> 0.558246).  Saving model ...\n",
            "Epoch [4/50], loss: 0.5390, accuracy: 0.7820: 100% 375/375 [00:01<00:00, 247.49it/s]\n",
            "Epoch 4/50 | Training Loss: 0.538960 | Val Loss: 0.543639 | Val Acc: 0.777898\n",
            "Validation loss decreased (0.558246 --> 0.543639).  Saving model ...\n",
            "Epoch [5/50], loss: 0.5261, accuracy: 0.7840: 100% 375/375 [00:02<00:00, 185.89it/s]\n",
            "Epoch 5/50 | Training Loss: 0.526124 | Val Loss: 0.533946 | Val Acc: 0.780059\n",
            "Validation loss decreased (0.543639 --> 0.533946).  Saving model ...\n",
            "Epoch [6/50], loss: 0.5147, accuracy: 0.7869: 100% 375/375 [00:01<00:00, 190.18it/s]\n",
            "Epoch 6/50 | Training Loss: 0.514744 | Val Loss: 0.527214 | Val Acc: 0.782386\n",
            "Validation loss decreased (0.533946 --> 0.527214).  Saving model ...\n",
            "Epoch [7/50], loss: 0.5094, accuracy: 0.7880: 100% 375/375 [00:01<00:00, 246.54it/s]\n",
            "Epoch 7/50 | Training Loss: 0.509442 | Val Loss: 0.533332 | Val Acc: 0.781444\n",
            "Epoch [8/50], loss: 0.5042, accuracy: 0.7891: 100% 375/375 [00:01<00:00, 247.71it/s]\n",
            "Epoch 8/50 | Training Loss: 0.504151 | Val Loss: 0.525881 | Val Acc: 0.785516\n",
            "Validation loss decreased (0.527214 --> 0.525881).  Saving model ...\n",
            "Epoch [9/50], loss: 0.0980, accuracy: 0.9681: 100% 375/375 [00:01<00:00, 242.73it/s]\n",
            "Epoch 9/50 | Training Loss: 0.098027 | Val Loss: 0.066870 | Val Acc: 0.980496\n",
            "Validation loss decreased (0.525881 --> 0.066870).  Saving model ...\n",
            "Epoch [10/50], loss: 0.0425, accuracy: 0.9872: 100% 375/375 [00:01<00:00, 247.20it/s]\n",
            "Epoch 10/50 | Training Loss: 0.042468 | Val Loss: 0.061652 | Val Acc: 0.983184\n",
            "Validation loss decreased (0.066870 --> 0.061652).  Saving model ...\n",
            "Epoch [11/50], loss: 0.0275, accuracy: 0.9923: 100% 375/375 [00:01<00:00, 242.00it/s]\n",
            "Epoch 11/50 | Training Loss: 0.027497 | Val Loss: 0.046269 | Val Acc: 0.986924\n",
            "Validation loss decreased (0.061652 --> 0.046269).  Saving model ...\n",
            "Epoch [12/50], loss: 0.0250, accuracy: 0.9935: 100% 375/375 [00:01<00:00, 235.01it/s]\n",
            "Epoch 12/50 | Training Loss: 0.025033 | Val Loss: 0.047268 | Val Acc: 0.986758\n",
            "Epoch [13/50], loss: 0.0241, accuracy: 0.9936: 100% 375/375 [00:01<00:00, 189.51it/s]\n",
            "Epoch 13/50 | Training Loss: 0.024066 | Val Loss: 0.044975 | Val Acc: 0.987589\n",
            "Validation loss decreased (0.046269 --> 0.044975).  Saving model ...\n",
            "Epoch [14/50], loss: 0.0230, accuracy: 0.9939: 100% 375/375 [00:01<00:00, 215.12it/s]\n",
            "Epoch 14/50 | Training Loss: 0.023047 | Val Loss: 0.045288 | Val Acc: 0.986758\n",
            "Epoch [15/50], loss: 0.0224, accuracy: 0.9939: 100% 375/375 [00:01<00:00, 246.07it/s]\n",
            "Epoch 15/50 | Training Loss: 0.022395 | Val Loss: 0.044238 | Val Acc: 0.987672\n",
            "Validation loss decreased (0.044975 --> 0.044238).  Saving model ...\n",
            "Epoch [16/50], loss: 0.0218, accuracy: 0.9943: 100% 375/375 [00:01<00:00, 247.39it/s]\n",
            "Epoch 16/50 | Training Loss: 0.021768 | Val Loss: 0.044302 | Val Acc: 0.987672\n",
            "Epoch [17/50], loss: 0.0211, accuracy: 0.9944: 100% 375/375 [00:01<00:00, 248.92it/s]\n",
            "Epoch 17/50 | Training Loss: 0.021150 | Val Loss: 0.044190 | Val Acc: 0.987672\n",
            "Validation loss decreased (0.044238 --> 0.044190).  Saving model ...\n",
            "Epoch [18/50], loss: 0.0205, accuracy: 0.9947: 100% 375/375 [00:01<00:00, 249.78it/s]\n",
            "Epoch 18/50 | Training Loss: 0.020457 | Val Loss: 0.044510 | Val Acc: 0.987755\n",
            "Epoch [19/50], loss: 0.0201, accuracy: 0.9947: 100% 375/375 [00:01<00:00, 245.12it/s]\n",
            "Epoch 19/50 | Training Loss: 0.020050 | Val Loss: 0.043223 | Val Acc: 0.988254\n",
            "Validation loss decreased (0.044190 --> 0.043223).  Saving model ...\n",
            "Epoch [20/50], loss: 0.0196, accuracy: 0.9948: 100% 375/375 [00:01<00:00, 199.71it/s]\n",
            "Epoch 20/50 | Training Loss: 0.019607 | Val Loss: 0.044828 | Val Acc: 0.987173\n",
            "Epoch [21/50], loss: 0.0184, accuracy: 0.9952: 100% 375/375 [00:01<00:00, 190.39it/s]\n",
            "Epoch 21/50 | Training Loss: 0.018389 | Val Loss: 0.043994 | Val Acc: 0.987422\n",
            "Epoch [22/50], loss: 0.0182, accuracy: 0.9954: 100% 375/375 [00:01<00:00, 248.22it/s]\n",
            "Epoch 22/50 | Training Loss: 0.018216 | Val Loss: 0.043873 | Val Acc: 0.987339\n",
            "Early stopping\n",
            "Accuracy: 0.9891 | F1 Score: 0.9890 | Precision: 0.9891 | Recall: 0.9890\n",
            "Class F1-score   Accuracy   Precision  Recall    \n",
            "0     0.9924     0.9939     0.9908     0.9939    \n",
            "1     0.9956     0.9965     0.9947     0.9965    \n",
            "2     0.9903     0.9932     0.9875     0.9932    \n",
            "3     0.9867     0.9901     0.9833     0.9901    \n",
            "4     0.9924     0.9919     0.9929     0.9919    \n",
            "5     0.9882     0.9888     0.9877     0.9888    \n",
            "6     0.9895     0.9875     0.9916     0.9875    \n",
            "7     0.9849     0.9825     0.9873     0.9825    \n",
            "8     0.9876     0.9846     0.9907     0.9846    \n",
            "9     0.9826     0.9812     0.9841     0.9812    \n"
          ]
        }
      ],
      "source": [
        "!python /content/Deep-Learning/Lab_3/Lab_3_BT1_2/training.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}